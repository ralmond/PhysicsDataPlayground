Overview

Project

**Game Design**

**Cognitive Supports**

> As part of the project, the team designed and developed a set of
> in-game cognitive supports. The iterative design and development
> process used is described in Shute, Smith et al. (2020)

-   ***Final set of in-game cognitive supports* (1) physics videos, (2)
    interactive definitions, (3) formulas, (4) Hewitt videos, (5)
    glossary, (6) worked examples, (7) hints, and (8) game tips.**

-   **Final Cognitive Support Design**

![A diagram of a company Description automatically
generated](media/image1.jpg){width="6.5in" height="3.65625in"}

**Affective Supports**

**Physics Assessments**

**Physics Understanding Test**

-   Research Studies: Game Design and Usability, Cognitive Supports,
    Learning and Stealth Assessment Research Studies

-   Overview: We created 36 illustrative multiple-choice items covering
    the nine physics competencies in the game, counterbalanced between
    two equivalent forms for a pretest and posttest (pretest = 18 items,
    *α* = .77; posttest = 18 items, *α* = .82). Each form includes two
    items per competency. The items were (a) designed in the context of
    the game (i.e., including a video or an image from the game
    environment), (b) developed with the help of two physics experts,
    and (c) subjected to several pilot tests before administration in
    the current study.

> **Physics Understanding Test**

-   Research Studies: Affective Supports, Support Timing, Support
    Efficacy

-   We created two isomorphic forms each including 28 illustrative
    multiple-choice items (Form A = 28 items, Cronbach's *α* = 0.80;
    Form B = 28 items, Cronbach's *α* = 0.83) covering the two physics
    competencies in (i.e., ECT and POT). Each form included 14
    near-transfer items (designed in the context of the game) and 14
    far-transfer items, designed to resemble the Force Concept Inventory
    (Hestenes et al., 1992); These items were developed with the help of
    two physics experts and subjected to several pilot tests.

Game

How to use

Gameplay

Incentives

Supports

**Cognitive Supports**

**Affective Supports**

Stealth Assessment

Competency Model

Evidence Model

Evidence Identification

Statistics

QMatrix

Research Studies

**Support Timing (see Rahimi, Shute, et. al., 2022)**

Due to the constraints of the COVID-19 pandemic, all research was
conducted online. We collected data from five cohorts of middle and high
school students between the Spring and Fall of 2020. Data were collected
from 204 participants, of which 149 were analyzed here. The first cohort
(n = 12) participated as a remote after-school program (students were
from across the US), the second (n = 16), and fourth (n = 12) cohorts
participated as a remote activity related to their class (i.e., students
of this cohort were classmates), the third (n = 69) cohort's students
were also classmates and had an option to participate remotely from home
or come to their class wearing masks (everyone had to login via Zoom;
researchers collected the data remotely with the help of teachers), and
the fifth cohort (n = 40) participated as a remote summer camp program.
Students' ages ranged from 12 to 17 years, and the sample was diverse
with respect to ethnicity and gender. Students who completed the study
received a certificate of participation in addition to other
performance-based incentives.

We used a between-subjects pretest-posttest design. Students were
randomly assigned into one of three conditions: (1) Before (n = 50): in
which supports (i.e., Physics Videos) were delivered before students
started a level; (2) After (n = 46): in which supports were delivered
after students solved or quit a level; and (3) Control (n = 53): in
which students did not receive supports during gameplay.

Students assigned to the Before condition received a message encouraging
them to watch a physics video (i.e., support) to help them prepare for
and solve the level they were about to enter. Students in the After
condition received a message when they solved or quit a level that
encouraged them to watch a physics video (i.e., support) that could help
them solve similar levels in the game.

The game version for this study included five tutorial levels, two
warmup levels, and 28 game levels with various difficulties targeting
the two physics concepts of energy can transfer (ECT) and properties of
torque (POT). We ordered all the levels from easy to difficult (r = .62
between level number and difficulty) to ease students' entry into the
game and ordered them in a way that students alternated between the two
concepts (ECT or POT). We also counterbalanced the ordering of levels
with associated supports in that half the students in each treatment
condition saw the supports in one set of 14 levels, and the other half
saw the supports in the other set of 14 levels. In total, 35 levels were
grouped within one large playground. Students played through these
levels during individual gameplay sessions. Students could freely
navigate through the game levels, although the game levels were
presented to them in a predetermined order.

We included each support (i.e., physics video) in two of the relevant
game levels to potentially increase exposure to the support and
facilitate generalization since the same support can be useful for
multiple levels. Also, students were required to watch the entire
physics video the first time it was presented to them during gameplay.
Specifically, the game was programmed to: (a) check if the student was
viewing the physics video for the first time, and (b) if a was true then
the game would wait until the physics video was completed before
providing a button to allow the students close the video window. In all
subsequent views of the physics video, students could close the video at
will. Students always had access to Hints during gameplay. Students
could also access Game Tips.

Measurement instruments included content (i.e., physics understanding),
affect (i.e., intrinsic motivation inventory), and game data. The game
records player actions and gameplay events into log files, such as: the
number of levels solved, number of gold coins, number of silver coins,
engagement with the physics videos (i.e., duration of views), and
duration of gameplay. We parsed and extracted these data from log files
for analysis.
